Computer vision has come a long way with the support of deep learning techniques. Deep learning solves the problem of extracting high-level abstract features from raw data\cite{goodfellow2016deep}. The computer vision community has already deployed deep learning in a wider range thanks to convolutional neural networks such as image classification, image retrieval, object detection, verification, semantic segmentation, autonomous driving, playing games, pose estimation,  image captioning, activity recognition etc. \cite{lecun1998gradient, krizhevsky2012imagenet, ren2015faster, long2015fully, xu2016end, taigman2014deepface,mnih2010learning, toshev2014deeppose,mnih2013playing,sermanet2011traffic} Autonomous driving can benefit from deep learning compromising different areas together such as object detection, pedestrian detection, localization and mapping, perception control, scene understanding etc. In this section we review the evolution of convolutional neural networks and recurrent neural networks as sequence models.

\subsection{Convolutional Neural Networks}
\label{se:cnn}

Conventional neural networks consists of neurons in each layer which are fully connected with the neurons in the previous and subsequent layers. Having this kind of neural network is inefficient in case where the input is pixel values of a raw image. The number of parameters will drastically increase and there will be tons of useless connections between neurons.
 
Convolutional Neural networks(CNN)\cite{lecun1989backpropagation} are a great solution to learn from images where small filters are employed on an entire image to output feature maps associated with each filter. CNNs are advantageous in terms of weight sharing which reduces the number of connections and parameters in a network and the fact that each filter can look for a particular entity or pattern within the entire image which adds ability to translate about weights learned from one area of image to other areas. Convolutional neural networks fastened the usage of deep learning in almost all the areas among computer vision community. LeNet\cite{lecun1998gradient} was among the first attempts to use CNN where the application was hand digit recognition. AlexNet\cite{krizhevsky2012imagenet} was the first CNN to win the famous ImageNet Challenge(ILSVRC)\cite{russakovsky2015imagenet} in 2012 which is a large scale visual recognition challenge for image classification. Since then all subsequent years have been won by CNN based networks which improves the CNN based architectures and made the networks deeper and deeper.\cite{zeiler2014visualizing, simonyan2014very, szegedy2015going, he2016deep, hu2017squeeze}. 

Architectures won image-net evolution show that in order to achieve a small improvement in error models get deeper and more complex. For example GoogLenet(2014)\cite{szegedy2015going} with 22 layers had an error rate of 6.7\% on ImageNet while the ResNet(2015)\cite{he2016deep} improves that error to 3.57\% with a total of 152 layers. Since making networks deeper and deeper is not the optimum solution for making neural networks more intelligent and adaptive, subsequent researches tried to either harvest more information within a layer such as pose and  orientation\cite{sabour2017dynamic, e2018matrix} or make the neural network adjustable in some manner, making fixed parameters also learnable and weights adjustable \cite{hu2017squeeze,Ha2016}. Including the attention component in neural networks is also an interesting finding where networks are trained to pay attention to particular parts of the inputs\cite{GregorDGW15, xu2015show}.


\subsection{Sequential Neural Networks}
\label{se:rnn}

CNNs are great for harvesting information from images i.e spatial information but lacks the ability to extract temporal information. Recurrent Neural Networks are an extension to conventional neural networks which is able to handle sequential data with variable length\cite{chung2014empirical}. However Bengio et al(1994)\cite{bengio1994learning} observed that training a conventional RNN is challenging because RNNs are subjective to inability of capturing long term dependencies\cite{bengio1994learning} and the gradient vanishing problem. One solution was to device better learning algorithms than gradient descent\cite{bengio2013advances,martens2011learning}. The other approach of designing better activation functions resulted Long Short Term Memory(LSTM)\cite{hochreiter1997long} and Gated Recurrent Unit(GRU)\cite{cho2014properties}. These were able to capture long term dependencies in sequential data which enhanced the usage of RNNs. 

Sequence models have been widely adopted covering number of areas such as language modeling\cite{mikolov2010recurrent}, character recognition and generation\cite{graves2013generating, GregorDGW15}, sequence to sequence translation\cite{sutskever2014sequence}, speech recognition\cite{graves2013speech}, image captioning\cite{vinyals2015show, karpathy2015deep} and video analysis\cite{donahue2015long}.


\subsection{Training a network}
\label{se:rl}

Training a deep neural network is a challenging task merely due to the large number of parameters. Apart from the learning algorithm used in a deep neural network, adjusting the weights of connections in a network is also an important task. Despite of the learning algorithm most widely used approach to train the weights of a neural network is back-propagation introduced by Rumelhart et al \cite{rumelhart1986learning}. Back-propagation repeatedly adjusts the weights of a neural network in order to minimize the distance between the actual output and the expected output of the network. Several improvements have been proposed to improve the training of large neural networks trying to address the problem of overfitting such as dropout\cite{srivastava2014dropout}, regularization\cite{krogh1992simple}, data augmentation and early stopping. Gradient vanishing is the problem where the weight updates become very small in a neural network mainly due to the size of the network and several approaches to overcome this issue have been proposed\cite{hochreiter1997long}\cite{he2016deep}


\subsection{Learning Algorithms}
\label{se:supervisedlearning}

In literature we observe three main types of learning algorithms to train a neural network which are supervised learning, unsupervised learning and reinforcement learning. Here we intend to discuss in detail about supervised and reinforcement learning as those two are the most commonly used approaches to learning of neural networks associated with computer vision. In supervised learning a model is given a dataset containing inputs and the associated outputs which are namely labels. Models are supposed to learn from these data and generalize to the unseen data in the validation and test sets. Unsupervised learning involves letting the model to learn from the data with no labels itself. Reinforcement learning imposes an objective function on an agent in an environment where the agent is supposed to take the optimal action based on the current state of the environment and possible future states which is then rewarded.

Current applications of deep learning mainly focus on supervised learning, however the use of additional unsupervised learning to facilitate supervised learning is also there\cite{schmidhuber2015deep}. Learning from demonstration\cite{stafylopatis1998autonomous} is a branch of supervised learning where the autonomous agent is supposed to learn from the human instructor's demonstration. There are navigation architectures which are trained in a supervised way\cite{pomerleau1989alvinn,bojarski2016end}

Reinforcement learning agent is supposed to learn without a teacher from occasional real-valued positive or negative rewards. They should discover and learn how to interact with a dynamic unknown environment in order to maximize expected cumulative future rewards.\cite{schmidhuber2015deep}. The recent development in reinforcement learning influenced in training agents for various tasks such as play video games\cite{mnih2013playing,silver2016mastering,silver2017mastering}, detection\cite{mnih2014recurrent} and autonomous driving in simulated environments\cite{abbeel2004apprenticeship,lillicrap2015continuous}. It is exciting to see RL agents being able to perform at human level\cite{mnih2015human} as well as surpassing human level\cite{silver2016mastering,silver2017mastering}.

Since the introduction of generative adversarial networks (GAN)\cite{goodfellow2014generative} extensive research has already been taken place with regard to GAN based image inpainting. Unlike conventional methods of generative modelling such as Variational Auto Encoders\cite{kingma2013auto}, Boltzmann Machines\cite{salakhutdinov2007restricted, salakhutdinov09},  GANs are able to model implicit intractable probability density functions and the training approach includes converging to a nash equilibrium of a game which is more difficult than optimizing an objective function\cite{goodfellow2016nips}. The deep convolutional generative adversarial networks (DCGAN) introduced in Radford et al.\cite{radford2015unsupervised} which proposed several improvements to the architectural topology of convolutional GAN which stabilized the training of GANs. This work inspired subsequent research on GANs which involved deep convolutional networks. Conventional GANs are using merely noise as input to the generator and the goal is to learn a distribution. Conditional GANs adds informative conditioning variable in addition to noise which lets the model to learn a conditional distribution. Conditional GANs have been deployed in generating images conditioned on class label\cite{mirza2014conditional}, conditioned on text\cite{reed2016generative}, conditioned on image\cite{isola2017image} etc.


 

 
